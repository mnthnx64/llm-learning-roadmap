# LLM Learning Workspace

This workspace is dedicated to learning about Large Language Models (LLMs) and related technologies.

## Structure

This repository is organized by learning topics:

- **nlp-foundation/**: Fundamentals of Natural Language Processing
  - `regex/`: Regular expressions for text processing
  - `text-preprocessing/`: Tokenization, stemming, lemmatization, NER, POS
  - `text-presentation/`: Count vectorizer, TF-IDF, BOW, Word2Vec, Embeddings
  - `text-classification/`: Na√Øve Bayes classification

- **gen-ai-fundamentals/**: Generative AI fundamentals
  - `llms-embeddings/`: Large Language Models and Embeddings
  - `vector-dbs/`: Vector Databases (FAISS, Chromadb)
  - `rag/`: Retrieval Augmented Generation
  - `langchain/`: Langchain Framework

- **project-1/**: Real-world projects
  - `real-world-projects/`: Projects using LLMs, RAG, Agents to solve real-life problems

- **agentic-ai-fundamentals/**: Agentic AI concepts
  - `what-is-agentic-ai/`: Understanding Agentic AI
  - `gen-ai-vs-agents/`: Gen AI vs AI Agents vs Agentic AI
  - `mcp/`: Model Context Protocol (MCP)

- **frameworks/**: AI agent frameworks
  - `agno/`: Building agents with Agno framework
  - `langgraph/`: Building stateful agents with LangGraph
  - `crew-ai/`: Crew AI framework
  - `google-adk/`: Google Agent Development Kit
  - `openai-adk/`: OpenAI Agent Development Kit
  - `langsmith/`: Tracing and monitoring with LangSmith

## Setup

1. Activate the mamba environment:
   ```bash
   mamba activate llm-learning
   ```

2. Install dependencies as needed for each topic (see individual folder READMEs)

## Roadmap

See [roadmap.md](./roadmap.md) for the complete learning roadmap.

